---
title: 如何善用大语言模型：扬长避短
description: 善用大语言模型，需遵循四大原则：认知分工、交叉验证、巧妙提问、扩展能力。
date: 2025-09-01 23:30:00 +0800
categories: [AI, cognize]
tags: [thinking]
---

大语言模型（LLM）的出现，标志着**人机交互范式的一次巨大变革**。

大语言模型是一种极其复杂的概率预测引擎——本质上是“高级自动补全”系统，是基于海量数据训练，预测文本序列中下一个可能出现的词。

它的确存在一些优势，比如：
- 知识广度：拥有大量基于事实的知识，涵盖了各个领域
- 自注意力机制：拥有工作记忆，可以结合上下文理解，并能区分内容的不同权重
- 擅长自然语言生成：能根据提示快速产出连贯、语法正确且风格多样的文本

但正如前文「警惕大语言模型的根本局限」中提到的**三大根本局限：缺乏真正的语义理解与意识、幻觉（Hallucination）问题无法根除、缺乏稳定的价值判断能力和一致性**。

其中尤为常见的短板是“幻觉”问题：模型有时会给出“看起来很有道理但实际错误”的回答。

大语言模型提供了前所未有的自动化文字处理能力，但“能说会道”不等于“言出必真”。**我们应充分利用其语言生成和知识整合优势，同时通过人类监督来避开其短板，在实际使用时做到扬长避短。**

## 扬长避短的四大原则

结合过去两年多的实践，关于如何善用大语言模型，我提炼出了四大原则：

- **认知分工**：最高效的人机交互模式是一种共创关系。将 LLM 占据优势的任务（如头脑风暴、内容合成、海量文本处理）分配给大模型，同时将需要人类参与的环节（如事实核查、复杂判断、价值选择）保留给专家。  
- **交叉验证**：LLM 生成的文本流畅、自信，使其极具吸引力和迷惑性，让人类放松警惕。但它无法根除的幻觉问题，要求我们必须采取一种“验证而非信任”的态度。
- **巧妙提问**：提示词是挖掘 LLM 能力、调整 LLM 生成结果的关键手段。撰写提示词的过程，能看出一个人的思考能力、以及他对大模型的理解深度。
- **扩展能力**：如果把 LLM 看作生产力工具，它可以在外部系统的加持下，拓展其能力，完成更复杂的任务。比如，采用检索增强生成技术提升回答准确率，或者通过工具调用参与世界实时互动。 

接下来，我们结合具体场景，逐个讲讲这些原则如何执行。

## 认知分工：建立人机共创的伙伴关系

“认知分工”的本质，是承认并利用人与大语言模型各自的认知优势，形成一种“1+1>2”的协作模式。**人类提供方向、把控质量、注入价值观，而 LLM 则作为强大的“思维辅助”，负责处理那些消耗认知带宽但创造性不高的任务。**

我们来看三个实际应用场景：

#### 场景一：内容创作与营销
- LLM 的“体力活”：当你需要为新产品撰写一系列营销文案时，可以让 LLM 进行头脑风暴，在几秒钟内生成数十个不同风格（如专业、幽默、感性）的广告语、社交媒体帖子、博客文章大纲。你甚至可以输入产品的核心卖点和目标用户画像，让它进行初步的内容填充。
- 人类的“脑力活”：营销专家接着介入，从 LLM 生成的众多选项中，筛选出最具潜力的几个。然后，结合自身对品牌调性、市场趋势和消费者心理的深刻理解，对文案进行精修、润色，注入情感和独特的品牌声音。最终的决策（采用哪个版本）和对市场反馈的复杂判断，仍由人类主导。

#### 场景二：法律文书与合同审阅

- LLM 的“体力活”：律师或法务人员可以将一份长达数十页的合同或法律文件输入 LLM，要求它快速总结关键条款、识别潜在的风险点（如模糊不清的表述、缺失的标准条款）、比对不同版本的差异，或将其翻译成通俗易懂的语言。这极大地节省了初步筛选和信息提取的时间。
- 人类的“脑力活”：LLM 的分析仅作为参考。资深律师必须亲自对这些“风险点”进行专业的法律评估，结合具体的商业背景、最新的法律法规和判例，做出精准的判断。合同的最终解释权、谈判策略的制定以及对法律后果的承担，完全依赖于人的专业智慧和责任心。

#### 场景三：科研与学术研究

- LLM 的“体力活”：研究人员在探索一个新领域时，可以让 LLM 快速梳理该领域的历史脉络、主要学派、关键论文和最新进展，形成一份全面的文献综述初稿。在处理大量实验数据时，LLM 可以辅助编写代码进行初步的数据清洗和可视化。
- 人类的“脑力活”：研究人员的核心任务是提出创新的研究假设、设计严谨的实验方案、对实验结果进行深入且批判性的解读，并最终形成具有洞见的学术观点。LLM 可以加速信息收集，但无法替代科学发现过程中那决定性的、源于人类好奇心和深刻思考的“灵光一现”。

“认知分工”的理念，重新定义了我们与AI的关系。并非用AI取代人类，而是将人类与AI整合成一个混合系统。在这个系统中，LLM 负责其擅长的概率性任务，如大规模数据筛选、模式识别和内容生成；而人类则负责其擅长的确定性任务，如批判性思维、事实核查和伦理判断。

至于**具体的实施过程，是搭建自动化工作流、或者完全手动协作，都可以依当下情况而定**。

## 交叉验证：验证优先于信任

大语言模型最令人着迷也最危险的特性，是其流畅、自信且极具说服力的表达。它总能用一种不容置疑的语气，讲述可能完全错误的信息。

这种与生俱来的“幻觉”问题，要求我们必须从根本上转变交互心态：**将 LLM 的回答视为一个有待验证的“假设”，而非一个可以直接采信的“事实”。建立严格的交叉验证流程，是驾驭 LLM 强大能力、规避其内在风险的唯一缰绳。**

那么，具体有哪些交叉验证的方法呢？

**第一种方法是多模型比对。**对同一问题，采用不同大模型（如GPT、Claude等）分别生成答案，比较其一致性与互补性。观察它们答案的共同点和差异点。

- **一致性检验**：如果多个顶级模型对事实性问题的回答高度一致，那么这个信息的可信度会显著增加。
- **互补性启发**：不同模型可能在分析角度、创意方向或知识覆盖面上各有千秋。一个模型可能提供更具结构化的答案，另一个则可能带来更具创造性的观点。比较它们，能帮我们拼凑出更全面、更立体的图景。

**第二个方法是外部权威验证。**将 LLM 的输出与公认的权威信息源进行直接比对。这是一种最基本也最可靠的验证手段。这里的“权威”取决于具体的领域。比如：

- 学术领域：可以查询 Google Scholar、PubMed、Web of Science 等学术数据库。
- 新闻数据：参考路透社、美联社等信誉良好的新闻机构，政府统计网站、世界银行等官方数据发布平台。
- 专业领域：可以检索官方发布的法律条文、行业标准文档、企业年报、产品技术手册等。

当 LLM 的输出与这些一手信源发生冲突时，必须优先采信一手信息源。

**第三种方法是结构化追问。**千万不要被动接受 LLM 的第一个答案。要像侦探一样，通过系列精心设计的追问来测试其回答的稳健性和一致性。具体可以这样操作：

- **追溯信源**：直接提问“你的这个结论是基于哪些信息来源？”“能否提供具体的文献或数据链接？”虽然 LLM 有时会杜撰来源，但这个过程本身就能筛选掉一部分不可靠的回答。
- **反向验证**：对它的关键结论设计“反向”或“挑战性”问题。例如，如果它断言“A策略是提升销量的最佳选择”，你可以追问：“在哪些情况下，A策略可能会失效？”或者“相比于B策略，A策略有哪些潜在的风险？”
- **深挖细节**：针对答案中的某个模糊或关键的细节，要求它提供更详尽的解释。例如，“你提到‘显著提升’，具体的数据指标是多少？这个‘显著’的判断标准是什么？”

通过这种压力测试，可以暴露其回答中存在的逻辑漏洞、事实错误或隐藏的假设，检查其知识是否真正自洽。

总之，我们有许多交叉验证的方法，综合评估答案的可靠性。**越是要求严格的场景，越需要采用多层多角度的验证以确保不出现错误。**

## 巧妙提问：成为与AI高效对话的提问者

如果说大语言模型是一个拥有海量知识和无穷潜力的“实习生”，那么提示词（Prompt）就是你这位“导师”用来引导它、启发它、塑造它的核心工具。提示词的质量，直接决定了这位“实习生”是敷衍了事地完成任务，还是能交付出远超预期的惊艳成果。

**撰写提示词，本质上是一种思维能力的修炼：它要求我们先在头脑中将模糊的需求清晰化、结构化，然后再用精准的语言传递出去。**

撰写提示词时，需要注意以下几点：

#### **1.清晰明确的意图表达**

一个优质的提示词，应该像电影导演给演员的“剧本”一样，包含所有必要的元素，让模型精准地进入角色、理解情境。一个屡试不爽的框架是**“角色 - 场景 - 目标 - 约束”**：

- 角色 (Role)：你希望模型扮演谁？“你是一位资深的风险投资分析师”、“你是一位擅长用比喻的科普作家”。
- 场景 (Context)：交代必要的背景信息。“我正在为一家初创的咖啡品牌撰写商业计划书。”
- 目标 (Task)：清晰、无歧义的任务指令。“分析其潜在的市场风险，并提出三条应对策略。”
- 约束 (Constraints)：明确输出的格式、风格、长度等要求。例如，“请用专业的商业术语，以无序列表的形式呈现，全文控制在300字以内。”

**举个例子，一位历史老师正在设计一堂关于“丝绸之路”的课程。**她使用一个精心设计的提示词：“{角色}你是一位经验丰富的中学历史课程设计师，{场景}面对一群对历史不太感兴趣的14岁学生。{目标}请设计一个45分钟的互动式课程大纲，{约束}要求包含至少一个小组讨论活动和一个多媒体展示环节，语言风格要生动有趣，避免枯燥的年份和人名堆砌。” 

通过这个提示词，她得到的是一个高度定制化且可执行的教学方案，而非泛泛的知识罗列。

**还有一个高级技巧：设定系统提示词 (System Prompt)。**对于需要贯穿整个对话的全局设定，可以使用系统提示词。例如，在对话开始前设定：“在我们的整个对话中，请始终扮演一个批判性思考者的角色，对我的每一个观点提出至少一个质疑。” 这能有效引导对话的价值观和互动模式。

#### **2.化繁为简，将一个大问题拆解为数个小问题**

面对一个宏大而复杂的任务（如“写一份完整的市场调研报告”），直接一步到位往往效果不佳。更聪明的做法是将其拆解成一系列逻辑清晰的子任务，通过多轮对话，像搭建脚手架一样，逐步引导模型构建出最终的成果。

**“写一份完整的市场调研报告”拆解示例：**

- 第一步（头脑风暴）：“针对‘智能家居’市场，帮我头脑风暴出5个可行的调研主题。”
- 第二步（确定大纲）：“很好，我们选择‘用户对隐私问题的担忧’这个主题。请为这个主题设计一份调研报告的大纲，包含引言、现状分析、用户访谈、结论建议等部分。”
- 第三步（逐段生成）：“现在，请先撰写‘现状分析’这一章，引用近两年的至少三项权威数据。”
- 第四步（反馈优化）：“这一段写得不错，但语气过于学术。请修改得更商业化一些，并加入一个关于欧洲 GDPR 法规影响的案例。”

如此一来，每一步都聚焦于一个简单任务，便于人类进行精准的反馈和调整，确保最终的合成品高度符合预期。

#### **3.复用与持续迭代**

在日常工作中，我们经常会遇到重复性的任务。将那些经过验证、能高效产出优质结果的提示词沉淀下来，建立个人或团队的“提示词库”（Prompt Library），是实现效率倍增的关键。

当你撰写了一个效果很不错的提示词后，将其记录在一个文档或专用的笔记软件中，并标注好其适用场景和关键变量。那么，下次遇到类似任务（如每周写工作周报），直接从库中调取模板，只需修改其中的几个关键变量（如本周的具体项目和数据），即可快速生成结果。

一旦你又掌握了新的技巧，发现某个提示词的输出效果可以进一步提升时，可以及时对其进行优化迭代，让你的“武器库”常磨常新。

此外，**别忘了大语言模型十分擅长照猫画虎，如果你能给它一个好的范例作为参考，它也会给你带来惊喜。**

## 扩展能力：从“孤立大脑”到“超级中枢”

孤立的 LLM 是一个强大的“大脑”，但当它与外部世界连接，其能力将呈指数级增长。通过技术手段，我们可以让 LLM 突破训练数据的限制，成为一个能够感知、行动、并与现实世界互动的超级中枢。

**当前已经出现了一些不同方向的技术手段来扩展现有 LLM 的能力。**

例如，**检索增强生成 (Retrieval-Augmented Generation, RAG)技术，是解决知识陈旧和幻觉问题的利器。**当用户提问时，系统首先利用关键词在外部知识库（如公司内部文档、最新的网络文章、专业数据库）中进行检索，找到最相关的几段信息。然后，将这些信息连同原始问题一起作为上下文，提交给 LLM，让它基于这些“新鲜”且可靠的资料来生成答案。

它让模型的回答不仅更准确、更新鲜，而且可溯源——你可以清楚地知道它的结论是基于哪一份具体文档或数据，**这对于需要高度事实准确性的场景至关重要**。

举个例子，一家大型咨询公司利用 RAG 技术，将过去十年所有的项目报告、市场分析、专家访谈纪要和内部培训材料整合进一个私有知识库。现在，任何一名员工都可以用自然语言提问：“请帮我总结一下我们为快消品行业客户做过的所有关于‘数字化转型’的项目，并列出其中最成功的三个案例的关键洞察。” 系统会精准地从海量文档中检索、整合，并生成一份高度浓缩的摘要，极大地提升了知识复用和决策效率。

**另一种技术，是工具调用。**通过教会 LLM 调用外部应用程序接口（API）或执行代码，它可以获取实时信息（如股票价格、天气预报），与软件交互（如预订会议）或执行精确计算。

工具调用打破了LLM与外部世界之间的壁垒，使其从一个“言说者” 变成一个“行动者”，极大地扩展了它的应用边界，使其能够无缝融入现有的工作流和软件生态，成为一个真正的“智能助理”。

近期业界关注的**智能体 (Agents) 可以被看作是 LLM 扩展能力的更高阶形态。**一个智能体 (Agent) 是一个以 LLM 为核心的系统，它被赋予一个宏大的目标，并被授权可以自主地思考、规划，循环使用多种工具来达成这个目标。它能自主将复杂任务分解成一系列子步骤，为每个步骤选择合适的工具（是搜索网络、是调用计算器、还是执行一段代码？），然后根据工具返回的结果，评估进展，并动态调整下一步的计划，直到最终目标达成。

**智能体范式让 LLM 从一个被动响应指令的工具，进化为一个能主动进行长链条、复杂推理和执行的“自主系统”。**它代表了人机协作的未来方向，即人类设定目标和约束，而 AI 负责具体的执行路径规划和操作。

**例如，一家跨国物流公司部署了一个供应链智能体。**当系统监测到一个港口因天气原因即将关闭（通过调用天气预报API），这个以LLM为核心的智能体会自动启动：它会规划替代运输路线（调用地图和物流API），计算不同路线的成本和时间（调用内部数据库和计算工具），与承运商系统沟通以确保运力（调用合作伙伴API），并最终自动更新订单状态，同时通知所有受影响的客户。整个过程无需人工干预，展现了AI作为复杂系统“指挥官”的终极潜力。

我们仍处于人机交互新范式的早期阶段，或许还无法看清未来AI系统的能力边界。

## 小结

你可以把这篇文章看作如何高效使用大语言模型（LLM）的指南。

为了扬长避短，我提出了**四大核心交互原则**：

- **认知分工：建立人机共创的伙伴关系。**将LLM擅长的任务（如头脑风暴、内容草稿、处理海量信息等“体力活”）交给模型，而人类则专注于需要批判性思维、事实核查、价值判断和最终决策的“脑力活”。

- **交叉验证：采取“验证而非信任”的态度。**由于“幻觉”问题无法避免，绝不能直接采信LLM的回答。必须通过以下方式进行验证：
  - 多模型比对：对比不同LLM的答案。
  - 外部权威验证：与学术数据库、官方报告等可靠信息源核对。
  - 结构化追问：通过追溯信源、反向提问和深挖细节来测试其回答的稳健性。

- **巧妙提问：将提示词视为引导和塑造模型输出的核心工具。**高质量的提示词应清晰、结构化，推荐使用 “角色 - 场景 - 目标 - 约束” 框架。同时，建议将复杂任务拆解成多个小步骤，并通过持续迭代优化，建立个人或团队的提示词库。

- **扩展能力：将孤立的LLM与外部系统连接**，使其从“孤立大脑”进化为能与世界互动的“超级中枢”。主要技术包括：
  - 检索增强生成: 连接外部知识库，让 LLM 基于最新、可靠的资料生成答案，减少幻觉。
  - 工具调用: 允许 LLM 调用 API 或代码，获取实时信息、执行操作，从“言说者”变为“行动者”。
  - 智能体: 更高阶的应用，LLM 能自主规划并使用多种工具，以完成复杂目标。

> 大语言模型不是一个简单的“问答机器”，而是一种全新的生产力范式。

**掌握认知分工、交叉验证、巧妙提问和扩展能力这四大原则，我们才能超越“把它当作高级搜索引擎”的初级阶段，真正释放其作为“思维伙伴”和“能力放大器”的巨大潜能，驾驭这场由 AI 驱动的认知革命。**

而这个过程，最终也将深化我们对自身思维方式的理解，让我们成为更高效、更智慧的思考者。

*最后，还有一个小小提示：在自己可接受的成本内，使用能力最强的大语言模型。评估 LLM 各项能力的排行榜可参考：https://lmarena.ai/leaderboard*